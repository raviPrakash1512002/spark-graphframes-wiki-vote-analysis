{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7PzrW9xHWZ1w"
      },
      "outputs": [],
      "source": [
        "# =======  BDA Assignment-1 : Wikipedia Vote Graph ========\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.5.0\n",
        "!pip install graphframes"
      ],
      "metadata": {
        "id": "gR7-K2DXYYyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, split, trim, when, explode, sum as spark_sum\n",
        "from math import comb\n",
        "from graphframes import GraphFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "VwOczbqNXDyk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spark session with GraphFrames\n",
        "spark = SparkSession.builder.appName(\"WikiVoteAnalysis\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.2-spark3.0-s_2.12\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# set checkpoint directory needed for WCC / SCC\n",
        "spark.sparkContext.setCheckpointDir(\"/tmp/graphframes-checkpoint\")"
      ],
      "metadata": {
        "id": "v9LE1I69XT6e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download & Load Dataset\n",
        "!wget -nc -O /content/wiki-Vote.txt.gz https://snap.stanford.edu/data/wiki-Vote.txt.gz\n",
        "!gunzip -f /content/wiki-Vote.txt.gz\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0e7Hut3XdAM",
        "outputId": "8c7874f4-df3e-49bd-fcd8-a9fbe3dc05d6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-20 14:06:19--  https://snap.stanford.edu/data/wiki-Vote.txt.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290339 (284K) [application/x-gzip]\n",
            "Saving to: ‘/content/wiki-Vote.txt.gz’\n",
            "\n",
            "/content/wiki-Vote. 100%[===================>] 283.53K   407KB/s    in 0.7s    \n",
            "\n",
            "2025-09-20 14:06:20 (407 KB/s) - ‘/content/wiki-Vote.txt.gz’ saved [290339/290339]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw = spark.read.text(\"/content/wiki-Vote.txt\")\n",
        "\n",
        "edges = (raw.filter(~col(\"value\").startswith(\"#\")).withColumn(\"parts\", split(trim(col(\"value\")), \"\\\\s+\"))\n",
        "         .withColumn(\"src\", col(\"parts\").getItem(0).cast(\"int\"))\n",
        "         .withColumn(\"dst\", col(\"parts\").getItem(1).cast(\"int\"))\n",
        "         .select(\"src\", \"dst\")\n",
        "         .filter(col(\"src\").isNotNull() & col(\"dst\").isNotNull())\n",
        "        )\n",
        "\n",
        "# remove selfloop and duplicate\n",
        "edges = edges.filter(col(\"src\") != col(\"dst\")).dropDuplicates()\n",
        "\n",
        "# vertice\n",
        "vertices = (edges.select(col(\"src\").alias(\"id\")).union(edges.select(col(\"dst\").alias(\"id\"))).distinct())\n",
        "\n",
        "g = GraphFrame(vertices, edges)\n",
        "\n",
        "# basic Graph Stat\n",
        "\n",
        "num_nodes = vertices.count()\n",
        "num_edges = edges.count()\n",
        "print(f\"Nodes: {num_nodes}, Edges: {num_edges}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwxYuXBtXvmv",
        "outputId": "23f80c97-5599-40c5-e767-49b34e445e1c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: 7115, Edges: 103689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 3: weakly connected component (WCC)\n",
        "\n",
        "wcc = g.connectedComponents()\n",
        "wcc_sizes = wcc.groupBy(\"component\").count().orderBy(\"count\", ascending=False)\n",
        "largest_wcc_nodes = wcc_sizes.first()[\"count\"]\n",
        "\n",
        "largest_comp = wcc_sizes.first()[\"component\"]\n",
        "wcc_edges = (wcc.join(edges, wcc.id == edges.src, \"inner\").filter(wcc.component == largest_comp))\n",
        "largest_wcc_edges = wcc_edges.count()\n",
        "\n",
        "print(f\"Largest WCC: {largest_wcc_nodes} nodes, {largest_wcc_edges} edges\")\n",
        "# # Visualize WCC distribution\n",
        "# wcc_sizes_pd = wcc_sizes.toPandas()\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.barplot(x=wcc_sizes_pd.index, y=wcc_sizes_pd['count'])\n",
        "# plt.yscale('log')\n",
        "# plt.title('Distribution of Weakly Connected Component Sizes', fontsize=16)\n",
        "# plt.xlabel('Component Rank (Sorted by Size)', fontsize=12)\n",
        "# plt.ylabel('Number of Nodes (Log Scale)', fontsize=12)\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.tight_layout()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihH109IoYIDx",
        "outputId": "f3f644ff-b257-4ba9-8361-d7ebc9c691e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest WCC: 7066 nodes, 103663 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: strongly connected components (SCC)\n",
        "\n",
        "scc = g.stronglyConnectedComponents(maxIter=10)\n",
        "scc_sizes = scc.groupBy(\"component\").count().orderBy(\"count\", ascending=False)\n",
        "largest_scc = scc_sizes.first()\n",
        "largest_scc_nodes = largest_scc['count']\n",
        "largest_scc_id = largest_scc['component']\n",
        "\n",
        "# find edge inside largest SCC properly\n",
        "scc_with_edges = (edges.join(scc.select(col(\"id\").alias(\"src\"), col(\"component\").alias(\"src_comp\")), on=\"src\")\n",
        "    .join(scc.select(col(\"id\").alias(\"dst\"), col(\"component\").alias(\"dst_comp\")), on=\"dst\")\n",
        ")\n",
        "\n",
        "largest_scc_edges = scc_with_edges.filter(\n",
        "    (col(\"src_comp\") == largest_scc_id) & (col(\"dst_comp\") == largest_scc_id)\n",
        ").count()\n",
        "\n",
        "print(f\"Largest SCC: {largest_scc_nodes} nodes, {largest_scc_edges} edges\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiNm-eOlYK5o",
        "outputId": "ec99cb39-4630-4e1c-a0be-d611ed5bb339"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest SCC: 1300 nodes, 39456 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 5: Clustering Coefficient & Triangle\n",
        "\n",
        "triangles = g.triangleCount()\n",
        "\n",
        "# total triangle -- each counted 3 time\n",
        "num_triangles = triangles.agg(spark_sum(\"count\")).first()[0] // 3\n",
        "\n",
        "# correctly calculate total number of connected triplet\n",
        "degrees = g.degrees.withColumn(\"degree\", col(\"degree\").cast(\"long\"))\n",
        "total_connected_triplets = degrees.agg(spark_sum(col(\"degree\") * (col(\"degree\") - 1) / 2)).first()[0]\n",
        "\n",
        "clustering = (triangles.join(g.degrees, \"id\").withColumn(\"local_cc\", when(col(\"degree\") < 2, 0.0).otherwise(col(\"count\") / (col(\"degree\") * (col(\"degree\") - 1) / 2)))\n",
        ")\n",
        "avg_clustering = clustering.agg({\"local_cc\": \"avg\"}).first()[0]\n",
        "\n",
        "fraction_closed = num_triangles / total_connected_triplets\n",
        "\n",
        "print(f\"Average Clustering Coefficient: {avg_clustering:.4f}\")\n",
        "print(f\"Number of Triangles: {num_triangles}\")\n",
        "print(f\"Fraction of Closed Triangles: {fraction_closed:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPRLJ-05YNTB",
        "outputId": "20ca5b0d-55d8-46d8-d9e6-1480ce00f80e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Clustering Coefficient: 0.1387\n",
            "Number of Triangles: 608389\n",
            "Fraction of Closed Triangles: 0.03829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Distance Metrics\n",
        "\n",
        "def distance_metrics(graph, sample_fraction=0.01):\n",
        "    sample_nodes = [row[\"id\"] for row in graph.vertices.sample(False, sample_fraction, seed=42).collect()]\n",
        "    if not sample_nodes:\n",
        "        return None, None\n",
        "\n",
        "    # use BFS for an estimate of shortest path\n",
        "    sp_df = g.shortestPaths(landmarks=sample_nodes)\n",
        "\n",
        "    distances_df = sp_df.select(explode(col(\"distances\")).alias(\"key\", \"distance\"))\n",
        "    all_distances = distances_df.select(\"distance\").rdd.map(lambda row: row[0]).collect()\n",
        "\n",
        "    if not all_distances:\n",
        "        return None, None\n",
        "\n",
        "    diameter = max(all_distances) if all_distances else None\n",
        "\n",
        "    all_distances.sort()\n",
        "    effective_diameter = all_distances[int(0.9 * len(all_distances))]\n",
        "    return diameter, effective_diameter\n",
        "\n",
        "diameter, eff_diameter = distance_metrics(g, sample_fraction=0.01)\n",
        "print(f\"Diameter: {diameter}, Effective Diameter: {eff_diameter}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY_IbJOlYPgp",
        "outputId": "6923d5a0-acfb-49ab-d694-8e5150058425"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diameter: 9, Effective Diameter: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 7: Comparison Report\n",
        "\n",
        "ground_truth = {\n",
        "    \"Nodes\": 7115,\n",
        "    \"Edges\": 103689,\n",
        "    \"Largest WCC (nodes)\": 7066,\n",
        "    \"Largest WCC (edges)\": 103663,\n",
        "    \"Largest SCC (nodes)\": 1300,\n",
        "    \"Largest SCC (edges)\": 39456,\n",
        "    \"Avg. clustering coefficient\": 0.1409,\n",
        "    \"Number of triangles\": 608389,\n",
        "    \"Fraction of closed triangles\": 0.04564,\n",
        "    \"Diameter\": 7,\n",
        "    \"Effective diameter\": 3.8\n",
        "}\n",
        "\n",
        "results = {\n",
        "    \"Nodes\": num_nodes,\n",
        "    \"Edges\": num_edges,\n",
        "    \"Largest WCC (nodes)\": largest_wcc_nodes,\n",
        "    \"Largest WCC (edges)\": largest_wcc_edges,\n",
        "    \"Largest SCC (nodes)\": largest_scc_nodes,\n",
        "    \"Largest SCC (edges)\": largest_scc_edges,\n",
        "    \"Avg. clustering coefficient\": avg_clustering,\n",
        "    \"Number of triangles\": num_triangles,\n",
        "    \"Fraction of closed triangles\": fraction_closed,\n",
        "    \"Diameter\": diameter,\n",
        "    \"Effective diameter\": eff_diameter\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    \"Metric\": ground_truth.keys(),\n",
        "    \"Ground Truth\": ground_truth.values(),\n",
        "    \"Your Compute\": results.values()\n",
        "})\n",
        "\n",
        "print(\"\\n ------------------------------ Comparison Report ---------------------\")\n",
        "print(\"\\n\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTSTxQCmYSyI",
        "outputId": "5142df89-b950-4dbf-953f-2759022429a4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ------------------------------ Comparison Report ---------------------\n",
            "\n",
            "\n",
            "                          Metric  Ground Truth   Your Compute\n",
            "0                          Nodes    7115.00000    7115.000000\n",
            "1                          Edges  103689.00000  103689.000000\n",
            "2            Largest WCC (nodes)    7066.00000    7066.000000\n",
            "3            Largest WCC (edges)  103663.00000  103663.000000\n",
            "4            Largest SCC (nodes)    1300.00000    1300.000000\n",
            "5            Largest SCC (edges)   39456.00000   39456.000000\n",
            "6    Avg. clustering coefficient       0.14090       0.138652\n",
            "7            Number of triangles  608389.00000  608389.000000\n",
            "8   Fraction of closed triangles       0.04564       0.038286\n",
            "9                       Diameter       7.00000       9.000000\n",
            "10            Effective diameter       3.80000       4.000000\n"
          ]
        }
      ]
    }
  ]
}